{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1972ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is for training the ATPC data with a 3D CNN\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../scripts\")\n",
    "from TrackReconstruction_functions import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"16\"\n",
    "import MinkowskiEngine as ME\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1849fade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 2060\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check for CUDA (NVIDIA) or MPS (Apple)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54e6751d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>energy</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122</td>\n",
       "      <td>-1554.677368</td>\n",
       "      <td>-1489.785767</td>\n",
       "      <td>1508.124512</td>\n",
       "      <td>0.034792</td>\n",
       "      <td>0nubb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122</td>\n",
       "      <td>-1543.320435</td>\n",
       "      <td>-1489.691711</td>\n",
       "      <td>1512.508423</td>\n",
       "      <td>0.094080</td>\n",
       "      <td>0nubb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122</td>\n",
       "      <td>-1538.769165</td>\n",
       "      <td>-1480.243164</td>\n",
       "      <td>1513.530762</td>\n",
       "      <td>0.042178</td>\n",
       "      <td>0nubb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>122</td>\n",
       "      <td>-1531.169312</td>\n",
       "      <td>-1484.254028</td>\n",
       "      <td>1508.881348</td>\n",
       "      <td>0.003365</td>\n",
       "      <td>0nubb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>122</td>\n",
       "      <td>-1531.922852</td>\n",
       "      <td>-1491.922974</td>\n",
       "      <td>1513.565308</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0nubb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>70151</td>\n",
       "      <td>-1226.355713</td>\n",
       "      <td>-2456.864014</td>\n",
       "      <td>3708.881348</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>Bkg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>70151</td>\n",
       "      <td>-1240.709229</td>\n",
       "      <td>-2467.480225</td>\n",
       "      <td>3718.807373</td>\n",
       "      <td>0.162111</td>\n",
       "      <td>Bkg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>70151</td>\n",
       "      <td>-1254.262695</td>\n",
       "      <td>-2465.050537</td>\n",
       "      <td>3709.687256</td>\n",
       "      <td>0.059494</td>\n",
       "      <td>Bkg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>70151</td>\n",
       "      <td>-1597.664429</td>\n",
       "      <td>-2015.367432</td>\n",
       "      <td>2807.327148</td>\n",
       "      <td>0.006204</td>\n",
       "      <td>Bkg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>70151</td>\n",
       "      <td>-1581.673584</td>\n",
       "      <td>-2022.716919</td>\n",
       "      <td>2788.730225</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>Bkg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11082735 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     event_id            x            y            z    energy   Type\n",
       "0         122 -1554.677368 -1489.785767  1508.124512  0.034792  0nubb\n",
       "1         122 -1543.320435 -1489.691711  1512.508423  0.094080  0nubb\n",
       "2         122 -1538.769165 -1480.243164  1513.530762  0.042178  0nubb\n",
       "3         122 -1531.169312 -1484.254028  1508.881348  0.003365  0nubb\n",
       "4         122 -1531.922852 -1491.922974  1513.565308  0.003935  0nubb\n",
       "..        ...          ...          ...          ...       ...    ...\n",
       "144     70151 -1226.355713 -2456.864014  3708.881348  0.001812    Bkg\n",
       "145     70151 -1240.709229 -2467.480225  3718.807373  0.162111    Bkg\n",
       "146     70151 -1254.262695 -2465.050537  3709.687256  0.059494    Bkg\n",
       "147     70151 -1597.664429 -2015.367432  2807.327148  0.006204    Bkg\n",
       "148     70151 -1581.673584 -2022.716919  2788.730225  0.003532    Bkg\n",
       "\n",
       "[11082735 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load in the signal metadata\n",
    "nubb_meta = pd.read_hdf(f\"/media/argon/HardDrive_8TB/Krishan/ATPC/trackreco/ATPC_0nubb/1bar/5percent/reco_filtered/ATPC_0nubb_1bar_5percent_filtered.h5\", \"MC/hits\")\n",
    "nubb_meta[\"Type\"] = \"0nubb\"\n",
    "nubb_meta[\"subType\"] = \"0nubb\"\n",
    "# display(nubb_meta) \n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Load in the background\n",
    "Bkg_meta = pd.DataFrame()\n",
    "Tl_meta = pd.DataFrame()\n",
    "Bi_meta = pd.DataFrame()\n",
    "\n",
    "Tl_meta = pd.read_hdf(f\"/media/argon/HardDrive_8TB/Krishan/ATPC/trackreco/ATPC_Tl_ion/1bar/5percent/reco_filtered/ATPC_Tl_ion_1bar_5percent_filtered.h5\", \"MC/hits\")\n",
    "Tl_meta[\"subType\"] = \"Tl\"\n",
    "Bi_meta = pd.read_hdf(f\"/media/argon/HardDrive_8TB/Krishan/ATPC/trackreco/ATPC_Bi_ion/1bar/5percent/reco_filtered/ATPC_Bi_ion_1bar_5percent_filtered.h5\", \"MC/hits\")\n",
    "Bi_meta[\"subType\"] = \"Bi\"\n",
    "single_meta = pd.read_hdf(f\"/media/argon/HardDrive_8TB/Krishan/ATPC/trackreco/ATPC_single/1bar/5percent/reco_filtered/ATPC_single_1bar_5percent_filtered.h5\", \"MC/hits\")\n",
    "single_meta[\"subType\"] = \"single\"\n",
    "\n",
    "Bkg_meta = pd.concat([Tl_meta, Bi_meta, single_meta])\n",
    "\n",
    "Bkg_meta[\"Type\"] = \"Bkg\"\n",
    "\n",
    "\n",
    "# display(Bkg_meta)\n",
    "\n",
    "df = pd.concat([nubb_meta, Bkg_meta])\n",
    "# df = df.drop(columns=['x_smear', 'y_smear', 'z_smear'])\n",
    "df = df[[\"event_id\", \"x\", \"y\", \"z\", \"energy\", \"Type\"]]\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "927d36b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>energy</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122</td>\n",
       "      <td>-1.098896</td>\n",
       "      <td>-1.057378</td>\n",
       "      <td>-0.649942</td>\n",
       "      <td>0.086234</td>\n",
       "      <td>0nubb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122</td>\n",
       "      <td>-1.090830</td>\n",
       "      <td>-1.057312</td>\n",
       "      <td>-0.647092</td>\n",
       "      <td>0.234576</td>\n",
       "      <td>0nubb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122</td>\n",
       "      <td>-1.087598</td>\n",
       "      <td>-1.050603</td>\n",
       "      <td>-0.646427</td>\n",
       "      <td>0.104714</td>\n",
       "      <td>0nubb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>122</td>\n",
       "      <td>-1.082201</td>\n",
       "      <td>-1.053451</td>\n",
       "      <td>-0.649450</td>\n",
       "      <td>0.007603</td>\n",
       "      <td>0nubb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>122</td>\n",
       "      <td>-1.082736</td>\n",
       "      <td>-1.058896</td>\n",
       "      <td>-0.646404</td>\n",
       "      <td>0.009030</td>\n",
       "      <td>0nubb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>70151</td>\n",
       "      <td>-0.865725</td>\n",
       "      <td>-1.744071</td>\n",
       "      <td>0.780961</td>\n",
       "      <td>0.003718</td>\n",
       "      <td>Bkg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>70151</td>\n",
       "      <td>-0.875918</td>\n",
       "      <td>-1.751610</td>\n",
       "      <td>0.787414</td>\n",
       "      <td>0.404792</td>\n",
       "      <td>Bkg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>70151</td>\n",
       "      <td>-0.885544</td>\n",
       "      <td>-1.749884</td>\n",
       "      <td>0.781485</td>\n",
       "      <td>0.148040</td>\n",
       "      <td>Bkg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>70151</td>\n",
       "      <td>-1.129425</td>\n",
       "      <td>-1.430578</td>\n",
       "      <td>0.194782</td>\n",
       "      <td>0.014707</td>\n",
       "      <td>Bkg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>70151</td>\n",
       "      <td>-1.118068</td>\n",
       "      <td>-1.435797</td>\n",
       "      <td>0.182691</td>\n",
       "      <td>0.008021</td>\n",
       "      <td>Bkg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11082735 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     event_id         x         y         z    energy   Type\n",
       "0         122 -1.098896 -1.057378 -0.649942  0.086234  0nubb\n",
       "1         122 -1.090830 -1.057312 -0.647092  0.234576  0nubb\n",
       "2         122 -1.087598 -1.050603 -0.646427  0.104714  0nubb\n",
       "3         122 -1.082201 -1.053451 -0.649450  0.007603  0nubb\n",
       "4         122 -1.082736 -1.058896 -0.646404  0.009030  0nubb\n",
       "..        ...       ...       ...       ...       ...    ...\n",
       "144     70151 -0.865725 -1.744071  0.780961  0.003718    Bkg\n",
       "145     70151 -0.875918 -1.751610  0.787414  0.404792    Bkg\n",
       "146     70151 -0.885544 -1.749884  0.781485  0.148040    Bkg\n",
       "147     70151 -1.129425 -1.430578  0.194782  0.014707    Bkg\n",
       "148     70151 -1.118068 -1.435797  0.182691  0.008021    Bkg\n",
       "\n",
       "[11082735 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def MinMaxScale(df, label):\n",
    "    # Min-Max scaling\n",
    "    var_min = df[label].min()\n",
    "    var_max = df[label].max()\n",
    "    df[label] = (df[label] - var_min) / (var_max - var_min)\n",
    "    return df\n",
    "\n",
    "# Function for Min-Max normalization\n",
    "def normalize_group(group):\n",
    "    # Avoid division by zero if a group has only one point or max == min\n",
    "    if group.max() == group.min():\n",
    "        return group * 0.0\n",
    "    return (group - group.min()) / (group.max() - group.min())\n",
    "\n",
    "# Normalize the columns\n",
    "xyz_mean = df[[\"x\", \"y\", \"z\"]].mean()\n",
    "xyz_std  = df[[\"x\", \"y\", \"z\"]].std()\n",
    "df[[\"x\", \"y\", \"z\"]] = (df[[\"x\", \"y\", \"z\"]] - xyz_mean) / xyz_std\n",
    "\n",
    "\n",
    "# Apply clipping to the energy\n",
    "df['energy'] = df['energy'].clip(upper=0.4)\n",
    "\n",
    "df = MinMaxScale(df, \"energy\")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f1c7fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume df has columns: event_id, x, y, z, energy, Type\n",
    "# Type: \"0nubb\" or \"Bkg\"\n",
    "df['label'] = (df['Type'] == \"0nubb\").astype(int)\n",
    "\n",
    "# Event-level labels\n",
    "event_labels = df.groupby('event_id')['label'].first()\n",
    "event_ids    = event_labels.index.values\n",
    "event_y      = event_labels.values\n",
    "\n",
    "# Split 70/20/10\n",
    "ev_tmp, ev_test, y_tmp, y_test   = train_test_split(event_ids, event_y, test_size=0.10, stratify=event_y, random_state=42)\n",
    "ev_train, ev_val, y_train, y_val = train_test_split(ev_tmp, y_tmp, test_size=2/9, stratify=y_tmp, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f404f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def voxelize_event(event_df):\n",
    "    \n",
    "    VOXEL_SIZE = 8.0 # mm\n",
    "\n",
    "    coords = event_df[['x','y','z']].values\n",
    "    energy = event_df[['energy']].values\n",
    "\n",
    "    coords = coords / VOXEL_SIZE\n",
    "    coords = coords.astype(int)\n",
    "\n",
    "    return coords, energy\n",
    "\n",
    "\n",
    "def merge_duplicates(coords, feats):\n",
    "\n",
    "    uniq, inv = np.unique(coords, axis=0, return_inverse=True)\n",
    "\n",
    "    merged_feats = np.zeros((len(uniq),1))\n",
    "\n",
    "    for i in range(len(feats)):\n",
    "        merged_feats[inv[i]] += feats[i]\n",
    "\n",
    "    return uniq, merged_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4070c9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventDataset(Dataset):\n",
    "    def __init__(self, events, labels):\n",
    "        self.events = events\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        event = self.events[idx]\n",
    "        coords, feats = voxelize_event(event)\n",
    "        coords, feats = merge_duplicates(coords, feats)\n",
    "\n",
    "        # batch_index added later in collate_fn\n",
    "        feats = torch.FloatTensor(feats).view(-1, feats.shape[1])\n",
    "        label = torch.LongTensor([self.labels[idx]])\n",
    "        return coords, feats, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.events)\n",
    "\n",
    "class SparseClassifier(ME.MinkowskiNetwork):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(D=3)\n",
    "\n",
    "        self.conv1 = ME.MinkowskiConvolution(1, 16, kernel_size=3, stride=1, dimension=3)\n",
    "        self.bn1   = ME.MinkowskiBatchNorm(16)\n",
    "        self.relu1 = ME.MinkowskiReLU()\n",
    "\n",
    "        self.conv2 = ME.MinkowskiConvolution(16, 32, kernel_size=3, stride=2, dimension=3)\n",
    "        self.bn2   = ME.MinkowskiBatchNorm(32)\n",
    "        self.relu2 = ME.MinkowskiReLU()\n",
    "\n",
    "        self.conv3 = ME.MinkowskiConvolution(32, 64, kernel_size=3, stride=2, dimension=3)\n",
    "        self.bn3   = ME.MinkowskiBatchNorm(64)\n",
    "        self.relu3 = ME.MinkowskiReLU()\n",
    "\n",
    "        self.pool  = ME.MinkowskiGlobalMaxPooling()\n",
    "        self.fc    = ME.MinkowskiLinear(64, 2)\n",
    "\n",
    "    def forward(self, coords, feats):\n",
    "\n",
    "        x = ME.SparseTensor(feats, coordinates=coords)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "\n",
    "        x = self.pool(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x.F   # convert SparseTensor → dense tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4ffee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_collate_fn(batch):\n",
    "    coords, feats, labels = [], [], []\n",
    "    for c, f, l in batch:\n",
    "        coords.append(c)\n",
    "        feats.append(f)\n",
    "        labels.append(l)\n",
    "    coords = ME.utils.batched_coordinates(coords)\n",
    "    feats  = torch.cat(feats, dim=0)\n",
    "    labels = torch.cat(labels)\n",
    "    return coords, feats, labels\n",
    "\n",
    "def make_event_list(df, event_ids):\n",
    "    grouped = df.groupby('event_id')\n",
    "    events = [grouped.get_group(eid).copy() for eid in event_ids]\n",
    "    labels = [g['label'].iloc[0] for g in events]\n",
    "    return events, labels\n",
    "\n",
    "train_events, train_labels = make_event_list(df, ev_train)\n",
    "val_events, val_labels     = make_event_list(df, ev_val)\n",
    "test_events, test_labels   = make_event_list(df, ev_test)\n",
    "\n",
    "train_dataset = EventDataset(train_events, train_labels)\n",
    "val_dataset   = EventDataset(val_events,   val_labels)\n",
    "test_dataset  = EventDataset(test_events,  test_labels)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 2000  # adjust based on GPU memory\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,  collate_fn=sparse_collate_fn)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False, collate_fn=sparse_collate_fn)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False, collate_fn=sparse_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d972bd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 16.481 | Val Loss: 4.849 | Val Acc: 0.514\n",
      "Epoch 2/10 | Train Loss: 16.376 | Val Loss: 4.849 | Val Acc: 0.491\n",
      "Epoch 3/10 | Train Loss: 16.380 | Val Loss: 4.902 | Val Acc: 0.480\n",
      "Epoch 4/10 | Train Loss: 16.361 | Val Loss: 5.395 | Val Acc: 0.487\n",
      "Epoch 5/10 | Train Loss: 16.350 | Val Loss: 4.950 | Val Acc: 0.487\n",
      "Epoch 6/10 | Train Loss: 16.366 | Val Loss: 4.979 | Val Acc: 0.480\n",
      "Epoch 7/10 | Train Loss: 16.352 | Val Loss: 5.279 | Val Acc: 0.483\n",
      "Epoch 8/10 | Train Loss: 16.355 | Val Loss: 4.881 | Val Acc: 0.487\n",
      "Epoch 9/10 | Train Loss: 16.355 | Val Loss: 5.085 | Val Acc: 0.487\n",
      "Epoch 10/10 | Train Loss: 16.351 | Val Loss: 4.920 | Val Acc: 0.479\n",
      "Test Accuracy: 0.475611542405156\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = SparseClassifier().cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "EPOCHS = 10  # adjust\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    # ---- train ----\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for coords, feats, y in train_loader:\n",
    "        coords, feats, y = coords.to(device), feats.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(coords, feats)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # ---- validate ----\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct  = 0\n",
    "    total    = 0\n",
    "    with torch.no_grad():\n",
    "        for coords, feats, y in val_loader:\n",
    "            coords, feats, y = coords.to(device), feats.to(device), y.to(device)\n",
    "            logits = model(coords, feats)\n",
    "            loss = criterion(logits, y)\n",
    "            val_loss += loss.item()\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    val_acc = correct / total\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {train_loss:.3f} | Val Loss: {val_loss:.3f} | Val Acc: {val_acc:.3f}\")\n",
    "\n",
    "# ================================\n",
    "# 9. Test evaluation\n",
    "# ================================\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total   = 0\n",
    "with torch.no_grad():\n",
    "    for coords, feats, y in test_loader:\n",
    "        coords, feats, y = coords.to(device), feats.to(device), y.to(device)\n",
    "        logits = model(coords, feats)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total   += y.size(0)\n",
    "\n",
    "print(\"Test Accuracy:\", correct / total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
