# nexus.sub

# The job title here.
# jobname=ATPC_0nubb
# jobname=ATPC_Tl
# jobname=ATPC_Bi
# jobname=ATPC_single
jobname=ATPC_Bi_ion


CONFIG=$(jobname).config.mac
INIT=$(jobname).init.mac

# script=SmearEvents.py
script=GetGammaInfo.py

# mode=CO2
# mode=Pressure
mode=25bar

OSDF_LOCATION=osdf:///ospool/ap40/data/krishan.mistry
HOME_LOCATION=/home/krishan.mistry/code/ATPC/

# newjobid = $(Process) + 100
#NewProcess = $INT(newjobid, %d)
NewProcess = $(Process)

executable = $(jobname)_job.sh
arguments = $(NewProcess) $(jobname) $(script) $(mode)

# Specify the name of the log, standard error, and standard output (or "screen output") files. Wherever you see $(Cluster), HTCondor will insert the 
#  queue number assigned to this set of jobs at the time of submission.
log    = jobs/$(jobname)/jobid$(NewProcess)/$(Cluster)_$(NewProcess).log
error  = jobs/$(jobname)/jobid$(NewProcess)/$(Cluster)_$(NewProcess).err
output = jobs/$(jobname)/jobid$(NewProcess)/$(Cluster)_$(NewProcess).out

# Transfer input files
# transfer_input_files = $(HOME_LOCATION)/config/$(INIT),$(HOME_LOCATION)/config/$(CONFIG),$(HOME_LOCATION)/notebooks/$(script),$(HOME_LOCATION)/notebooks/CompressEvents.py
transfer_input_files = $(HOME_LOCATION)/config/$(INIT),$(HOME_LOCATION)/config/$(CONFIG),$(HOME_LOCATION)/scripts/$(script),$(HOME_LOCATION)/notebooks/CompressEvents.py

# Transfer output files
transfer_output_remaps = "$(jobname).tar = $(OSDF_LOCATION)/job/ATPC/Pressure/$(jobname)/$(jobname)_$(Cluster)_$(NewProcess).tar"

# Specify Job duration category as "Medium" (expected runtime <10 hr) or "Long" (expected runtime <20 hr). 
#+JobDurationCategory = "Medium"
+JobDurationCategory = "Long"

# Use a singularity image to submit the file. The image should be stored in the protected area of your workspace
#+SingularityImage = "$(OSDF_LOCATION)/containers/docker_nexus_ATPC5.sif"
+SingularityImage = "$(OSDF_LOCATION)/containers/docker_nexus_ATPC9.sif"


# Tell HTCondor requirements (e.g., operating system) your job needs, 
# what amount of compute resources each job will need on the computer where it runs.
requirements = (Arch == "X86_64" && TARGET.GLIDEIN_ResourceName =!= "Lehigh - Hawk" && TARGET.GLIDEIN_ResourceName =!= "UA-LR-ITS-EP")
request_cpus = 1
request_memory = 4GB
request_disk = 5GB

# If submitting more than 10k jobs use this statement
max_idle = 2000

# Tell HTCondor the number of instances to run:
queue 5000