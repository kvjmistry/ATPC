# nexus.sub

# The job title here.
jobname=ATPC_0nubb
# jobname=ATPC_single
# jobname=ATPC_Bi_ion
# jobname=ATPC_Tl_ion

CONFIG=$(jobname).config.mac
INIT=$(jobname).init.mac

# mode=CO2
# mode=Pressure
mode=1bar

OSDF_LOCATION=osdf:///ospool/ap40/data/krishan.mistry
HOME_LOCATION=/home/krishan.mistry/code/ATPC/

# newjobid = $(Process) + 100
#NewProcess = $INT(newjobid, %d)
NewProcess = $(Process)

executable = $(jobname)_job.sh
arguments = $(NewProcess) $(jobname) $(mode)

# Specify the name of the log, standard error, and standard output (or "screen output") files. Wherever you see $(Cluster), HTCondor will insert the 
#  queue number assigned to this set of jobs at the time of submission.
log    = jobs/$(jobname)/$(mode)/jobid$(NewProcess)/$(Cluster)_$(NewProcess).log
error  = jobs/$(jobname)/$(mode)/jobid$(NewProcess)/$(Cluster)_$(NewProcess).err
output = jobs/$(jobname)/$(mode)/jobid$(NewProcess)/$(Cluster)_$(NewProcess).out

# Transfer input files
# transfer_input_files = $(HOME_LOCATION)/config/$(INIT),$(HOME_LOCATION)/config/$(CONFIG),$(HOME_LOCATION)/notebooks/$(script),$(HOME_LOCATION)/notebooks/CompressEvents.py
transfer_input_files = $(HOME_LOCATION)/config/$(INIT),$(HOME_LOCATION)/config/$(CONFIG),$(HOME_LOCATION)/config/Bi214.mac,$(HOME_LOCATION)/scripts/GetGammaInfo.py,$(HOME_LOCATION)/scripts/SmearEnergy.py,$(HOME_LOCATION)/scripts/SmearEvents.py,$(HOME_LOCATION)/scripts/GetTrueInfo.py,$(HOME_LOCATION)/scripts/TrackReconstruction_functions.py,$(HOME_LOCATION)/config/$(CONFIG),$(HOME_LOCATION)/config/Xe137.mac

# Transfer output files
transfer_output_remaps = "$(jobname).tar = $(OSDF_LOCATION)/job/ATPC/Pressure/$(jobname)/$(jobname)_$(Cluster)_$(NewProcess).tar"

# Specify Job duration category as "Medium" (expected runtime <10 hr) or "Long" (expected runtime <20 hr). 
#+JobDurationCategory = "Medium"
+JobDurationCategory = "Long"

# Use a singularity image to submit the file. The image should be stored in the protected area of your workspace
container_image = osdf:///ospool/ap40/data/krishan.mistry/containers/docker_nexus_ATPC11.sif


# Tell HTCondor requirements (e.g., operating system) your job needs, 
# what amount of compute resources each job will need on the computer where it runs.
requirements = (Arch == "X86_64" && TARGET.GLIDEIN_ResourceName =!= "Lehigh - Hawk" && TARGET.GLIDEIN_ResourceName =!= "UA-LR-ITS-EP")
request_cpus = 1
request_memory = 4GB
request_disk = 5GB

# If submitting more than 10k jobs use this statement
max_idle = 2000

# Tell HTCondor the number of instances to run:
queue 3000